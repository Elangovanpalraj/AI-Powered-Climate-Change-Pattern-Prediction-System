{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10987284",
   "metadata": {},
   "source": [
    "# Importing Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45b42596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9992\\1564586794.py\", line 7, in <module>\n",
      "    import tensorflow as tf #Initializing the ANN\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.eager import context\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 33, in <module>\n",
      "    from tensorflow.python.client import pywrap_tf_session\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\client\\pywrap_tf_session.py\", line 19, in <module>\n",
      "    from tensorflow.python.client._pywrap_tf_session import *\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'builder' from 'google.protobuf.internal' (C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\internal\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import numpy as np  # Linear algebra.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# import pandas as pd  # Data processing.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# from sklearn.impute import SimpleImputer# Univariate imputer for completing missing values with simple strategies.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# from sklearn.preprocessing import LabelEncoder  # Encode target labels.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# from sklearn.preprocessing import StandardScaler # Standardize features by removing the mean and scaling to unit variance.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# from sklearn.model_selection import train_test_split # Splits The data to test and train sets.\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m \u001b[38;5;66;03m#Initializing the ANN\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# import sklearn.metrics as sm\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# # import plotly.io as pio\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# # import plotly.express as px\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py:37\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m coordination_config_pb2\n\u001b[0;32m     46\u001b[0m GRAPH_MODE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     47\u001b[0m EAGER_MODE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\tsl\\protobuf\\coordination_config_pb2.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Generated by the protocol buffer compiler.  DO NOT EDIT!\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# source: tensorflow/tsl/protobuf/coordination_config.proto\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"Generated protocol buffer code.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'builder' from 'google.protobuf.internal' (C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\internal\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# import numpy as np  # Linear algebra.\n",
    "# import pandas as pd  # Data processing.\n",
    "# from sklearn.impute import SimpleImputer# Univariate imputer for completing missing values with simple strategies.\n",
    "# from sklearn.preprocessing import LabelEncoder  # Encode target labels.\n",
    "# from sklearn.preprocessing import StandardScaler # Standardize features by removing the mean and scaling to unit variance.\n",
    "# from sklearn.model_selection import train_test_split # Splits The data to test and train sets.\n",
    "import tensorflow as tf #Initializing the ANN\n",
    "# import sklearn.metrics as sm\n",
    "# # import plotly.io as pio\n",
    "# # import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20dfe65b-89d3-49d7-ac5e-232f336d8b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.30)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (18.1.1)\n",
      "Collecting numpy<1.24,>=1.22 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached numpy-1.23.5-cp310-cp310-win_amd64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached protobuf-4.25.6-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.71.0)\n",
      "Collecting tensorboard<2.13,>=2.12 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.13,>=2.12.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.4.30)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.15.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.39.0)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.32.3)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Using cached numpy-1.23.5-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "Using cached protobuf-4.25.6-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, numpy, keras, google-auth-oauthlib, tensorboard\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.10.0\n",
      "    Uninstalling tensorflow-estimator-2.10.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.10.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.10.0\n",
      "    Uninstalling keras-2.10.0:\n",
      "      Successfully uninstalled keras-2.10.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.6\n",
      "    Uninstalling google-auth-oauthlib-0.4.6:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.10.1\n",
      "    Uninstalling tensorboard-2.10.1:\n",
      "      Successfully uninstalled tensorboard-2.10.1\n",
      "Successfully installed google-auth-oauthlib-1.0.0 keras-2.12.0 numpy-1.23.5 protobuf-4.25.6 tensorboard-2.12.3 tensorboard-data-server-0.7.2 tensorflow-estimator-2.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\google\\~rotobuf'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~-mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~=mpy'.\n",
      "  You can safely remove it manually.\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "moviepy 2.1.2 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
      "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
      "scikit-image 0.25.2 requires pillow>=10.1, but you have pillow 10.0.0 which is incompatible.\n",
      "torchvision 0.15.2+cpu requires torch==2.0.1, but you have torch 2.6.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a14f953f-6647-4e25-a72e-07cdef57fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.24.4Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Uninstalling numpy-1.24.4:\n",
      "  Successfully uninstalled numpy-1.24.4\n",
      "Found existing installation: scipy 1.10.1\n",
      "Uninstalling scipy-1.10.1:\n",
      "  Successfully uninstalled scipy-1.10.1\n"
     ]
    }
   ],
   "source": [
    "pip uninstall numpy scipy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3995c30f-03de-4746-9ef0-6e51f9e15b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scikit-learn 1.6.1\n",
      "Uninstalling scikit-learn-1.6.1:\n",
      "  Successfully uninstalled scikit-learn-1.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall scikit-learn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e9ba23e-de87-43ea-b5bf-5940ac98c07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.2)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Using cached scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "Successfully installed scikit-learn-1.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~-learn'.\n",
      "  You can safely remove it manually.\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a02984f",
   "metadata": {},
   "source": [
    "# Dataset1 (Amman Airport)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89b67f94-ab01-4b26-8648-c219f3cb5cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.24.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.24.4)\n",
      "Requirement already satisfied: scipy==1.10.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: scikit-learn==1.2.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: jupyter in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn==1.2.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn==1.2.2) (3.6.0)\n",
      "Requirement already satisfied: notebook in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter) (7.4.0)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter) (8.1.5)\n",
      "Requirement already satisfied: jupyterlab in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter) (4.4.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter) (1.8.13)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter) (8.35.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter) (26.4.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets->jupyter) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets->jupyter) (3.0.13)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-console->jupyter) (3.0.50)\n",
      "Requirement already satisfied: pygments in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-console->jupyter) (2.19.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyterlab->jupyter) (2.0.5)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyterlab->jupyter) (3.1.6)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyterlab->jupyter) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyterlab->jupyter) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyterlab->jupyter) (65.5.0)\n",
      "Requirement already satisfied: tomli>=1.2.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyterlab->jupyter) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert->jupyter) (4.13.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert->jupyter) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert->jupyter) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert->jupyter) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from async-lru>=1.0.0->jupyterlab->jupyter) (4.13.2)\n",
      "Requirement already satisfied: webencodings in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.7)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (310)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.21.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.15)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.31.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.21.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (21.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.24.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->jupyter) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.3.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: fqdn in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.9.0.20241206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.24.4 scipy==1.10.1 scikit-learn==1.2.2 jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2643036a-9b88-498b-9463-34c9e6e865be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee2941e-201c-40e1-bd99-2f3efa260464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02311888-c922-4bbc-bbd0-8be7431678d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a89830a-b2c0-49cb-8f23-554bcd1e9b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Collecting scipy==1.11.4\n",
      "  Using cached scipy-1.11.4-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scikit-learn==1.3.2\n",
      "  Downloading scikit_learn-1.3.2-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn==1.3.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn==1.3.2) (3.6.0)\n",
      "Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.6/15.8 MB 12.0 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.4/15.8 MB 9.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.7/15.8 MB 7.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.0/15.8 MB 7.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 8.1/15.8 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.7/15.8 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.1/15.8 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.9/15.8 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 8.2 MB/s eta 0:00:00\n",
      "Using cached scipy-1.11.4-cp310-cp310-win_amd64.whl (44.1 MB)\n",
      "Downloading scikit_learn-1.3.2-cp310-cp310-win_amd64.whl (9.3 MB)\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.4/9.3 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.7/9.3 MB 11.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.0/9.3 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.1/9.3 MB 8.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.1/9.3 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.9/9.3 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.3 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.3/9.3 MB 5.8 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, scipy, scikit-learn\n",
      "Successfully installed numpy-1.26.4 scikit-learn-1.3.2 scipy-1.11.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.5.0 requires requests>=2.32.2, but you have requests 2.31.0 which is incompatible.\n",
      "scikit-image 0.25.2 requires pillow>=10.1, but you have pillow 10.0.0 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires keras<2.13,>=2.12.0, but you have keras 2.10.0 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires tensorboard<2.13,>=2.12, but you have tensorboard 2.10.1 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires tensorflow-estimator<2.13,>=2.12.0, but you have tensorflow-estimator 2.10.0 which is incompatible.\n",
      "torchvision 0.15.2+cpu requires torch==2.0.1, but you have torch 2.6.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.26.4 scipy==1.11.4 scikit-learn==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89170e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data.\n",
    "data1 = pd.read_excel('Amman Airport 01-01-2000 --- 31-05-2022.xlsx',\n",
    "                      header=5, na_values=['Null'], parse_dates=['Date/Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3a190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns.\n",
    "data1 = data1.drop(columns=['Station', 'Manual Present Weather ',\n",
    "                   'Cloud Type', 'Unnamed: 16', 'Unnamed: 17', 'Wind Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91cafe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new columns.\n",
    "data1['Area'] = 'Amman Airport'\n",
    "data1['Latitude'] = 31.59\n",
    "data1['Longitude'] = 35.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f4a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace (sky obscured or cloud amount cannot be estimated) with Nan value.\n",
    "data1['Clouds Cover (Okta)'] = data1['Clouds Cover (Okta)'].replace(\n",
    "    r'sky obscured or cloud amount cannot be estimated', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a07e3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the columns.\n",
    "data1.insert(1, 'Area', data1.pop('Area'))\n",
    "data1.insert(2, 'Latitude', data1.pop('Latitude'))\n",
    "data1.insert(3, 'Longitude', data1.pop('Longitude'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed068d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 217778 entries, 0 to 217777\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count   Dtype         \n",
      "---  ------                       --------------   -----         \n",
      " 0   Date/Time                    217778 non-null  datetime64[ns]\n",
      " 1   Area                         217778 non-null  object        \n",
      " 2   Latitude                     217778 non-null  float64       \n",
      " 3   Longitude                    217778 non-null  float64       \n",
      " 4   Air Dew Point                217778 non-null  float64       \n",
      " 5   Air Temperature (OC)         217778 non-null  float64       \n",
      " 6   Humidity %                   217778 non-null  float64       \n",
      " 7   Atmospheric Pressure         217778 non-null  float64       \n",
      " 8   Liquid Precipitation         217778 non-null  float64       \n",
      " 9   Clouds Cover (Okta)          217778 non-null  float64       \n",
      " 10  Cloud Cover %                217778 non-null  float64       \n",
      " 11  Snow Depth                   217778 non-null  float64       \n",
      " 12  Horizontal Visibility In m.  217778 non-null  float64       \n",
      " 13  Wind Direction (Degrees)     217778 non-null  float64       \n",
      " 14  Wind Speed (MPS)             217778 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(13), object(1)\n",
      "memory usage: 24.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Fixing missing data.\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data1['Snow Depth'].values.reshape(-1, 1))\n",
    "data1['Snow Depth'] = simpleImputer.transform(\n",
    "    data1['Snow Depth'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data1['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "data1['Wind Direction (Degrees)'] = simpleImputer.transform(\n",
    "    data1['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data1.iloc[:, 4:11])\n",
    "data1.iloc[:, 4:11] = simpleImputer.transform(data1.iloc[:, 4:11])\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data1['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "data1['Horizontal Visibility In m.'] = simpleImputer.transform(\n",
    "    data1['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data1['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data1['Wind Speed (MPS)'] = simpleImputer.transform(\n",
    "    data1['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f71ca",
   "metadata": {},
   "source": [
    "# Dataset2 (Aqaba Airport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e18d8bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the data.\n",
    "data2 = pd.read_excel('Aqaba Airport  01-01-2000 --- 31-05-2022.xlsx',\n",
    "                      header=5, na_values=['Null'], parse_dates=['Date/Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "638294ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%% Drop useless columns.\n",
    "data2 = data2.drop(columns=[\n",
    "                   'Station', 'Manual Present Weather ', 'Cloud Type', 'Unnamed: 16', 'Wind Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f5e77ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%% Add a new columns.\n",
    "data2['Area'] = 'Aqaba Airport'\n",
    "data2['Latitude'] = 29.3300\n",
    "data2['Longitude'] = 35.0000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa3415e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace (sky obscured or cloud amount cannot be estimated) with Nan value.\n",
    "data2['Clouds Cover (Okta)'] = data2['Clouds Cover (Okta)'].replace(\n",
    "    r'sky obscured or cloud amount cannot be estimated', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cde604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the columns.\n",
    "data2.insert(1, 'Area', data2.pop('Area'))\n",
    "data2.insert(2, 'Latitude', data2.pop('Latitude'))\n",
    "data2.insert(3, 'Longitude', data2.pop('Longitude'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d589b5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 184113 entries, 0 to 184112\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count   Dtype         \n",
      "---  ------                       --------------   -----         \n",
      " 0   Date/Time                    184113 non-null  datetime64[ns]\n",
      " 1   Area                         184113 non-null  object        \n",
      " 2   Latitude                     184113 non-null  float64       \n",
      " 3   Longitude                    184113 non-null  float64       \n",
      " 4   Air Dew Point                184113 non-null  float64       \n",
      " 5   Air Temperature (OC)         184113 non-null  float64       \n",
      " 6   Humidity %                   184113 non-null  float64       \n",
      " 7   Atmospheric Pressure         184113 non-null  float64       \n",
      " 8   Liquid Precipitation         184113 non-null  float64       \n",
      " 9   Clouds Cover (Okta)          184113 non-null  float64       \n",
      " 10  Cloud Cover %                184113 non-null  float64       \n",
      " 11  Snow Depth                   184113 non-null  float64       \n",
      " 12  Horizontal Visibility In m.  184113 non-null  float64       \n",
      " 13  Wind Direction (Degrees)     184113 non-null  float64       \n",
      " 14  Wind Speed (MPS)             184113 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(13), object(1)\n",
      "memory usage: 21.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Fixing missing data.\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data2['Snow Depth'].values.reshape(-1, 1))\n",
    "data2['Snow Depth'] = simpleImputer.transform(\n",
    "    data2['Snow Depth'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data2['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "data2['Wind Direction (Degrees)'] = simpleImputer.transform(\n",
    "    data2['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data2.iloc[:, 4:11])\n",
    "data2.iloc[:, 4:11] = simpleImputer.transform(data2.iloc[:, 4:11])\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data2['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "data2['Horizontal Visibility In m.'] = simpleImputer.transform(\n",
    "    data2['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data2['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data2['Wind Speed (MPS)'] = simpleImputer.transform(\n",
    "    data2['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f105fde6",
   "metadata": {},
   "source": [
    "# Dataset3 (Queen Alia Airport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2533cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data.\n",
    "data3 = pd.read_excel('Queen Alia Airport   01-01-2000 --- 08-12-2022.xlsx',\n",
    "                      header=5, na_values=['Null'], parse_dates=['Date/Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9de6a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns.\n",
    "data3 = data3.drop(\n",
    "    columns=['Station', 'Manual Present Weather ', 'Cloud Type', 'Wind Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37dec5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new columns.\n",
    "data3['Area'] = 'Queen Alia Airport'\n",
    "data3['Latitude'] = 31.4300\n",
    "data3['Longitude'] = 35.5900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af4c3495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace (sky obscured or cloud amount cannot be estimated) with Nan value.\n",
    "data3['Clouds Cover (Okta)'] = data3['Clouds Cover (Okta)'].replace(\n",
    "    r'sky obscured or cloud amount cannot be estimated', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8165823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming cloumns to match with the other datasets.\n",
    "data3.rename(columns={'Snow Depth.depth In CM': 'Snow Depth'}, inplace=True)\n",
    "data3.rename(columns={'liquid Precipitation depth In MM': 'Liquid Precipitation'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebff49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the columns.\n",
    "data3.insert(1, 'Area', data3.pop('Area'))\n",
    "data3.insert(2, 'Latitude', data3.pop('Latitude'))\n",
    "data3.insert(3, 'Longitude', data3.pop('Longitude'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ce93702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 217477 entries, 0 to 217476\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count   Dtype         \n",
      "---  ------                       --------------   -----         \n",
      " 0   Date/Time                    217477 non-null  datetime64[ns]\n",
      " 1   Area                         217477 non-null  object        \n",
      " 2   Latitude                     217477 non-null  float64       \n",
      " 3   Longitude                    217477 non-null  float64       \n",
      " 4   Air Dew Point                217477 non-null  float64       \n",
      " 5   Air Temperature (OC)         217477 non-null  float64       \n",
      " 6   Humidity %                   217477 non-null  float64       \n",
      " 7   Atmospheric Pressure         217477 non-null  float64       \n",
      " 8   Liquid Precipitation         217477 non-null  float64       \n",
      " 9   Clouds Cover (Okta)          217477 non-null  float64       \n",
      " 10  Cloud Cover %                217477 non-null  float64       \n",
      " 11  Snow Depth                   217477 non-null  float64       \n",
      " 12  Horizontal Visibility In m.  217477 non-null  float64       \n",
      " 13  Wind Direction (Degrees)     217477 non-null  float64       \n",
      " 14  Wind Speed (MPS)             217477 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(13), object(1)\n",
      "memory usage: 24.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Fixing missing data.\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data3['Snow Depth'].values.reshape(-1, 1))\n",
    "data3['Snow Depth'] = simpleImputer.transform(\n",
    "    data3['Snow Depth'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data3['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "data3['Wind Direction (Degrees)'] = simpleImputer.transform(\n",
    "    data3['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data3.iloc[:, 4:11])\n",
    "data3.iloc[:, 4:11] = simpleImputer.transform(data3.iloc[:, 4:11])\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data3['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "data3['Horizontal Visibility In m.'] = simpleImputer.transform(\n",
    "    data3['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data3['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data3['Wind Speed (MPS)'] = simpleImputer.transform(\n",
    "    data3['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5391f0f7",
   "metadata": {},
   "source": [
    "# Dataset4 (Ghor El Safi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c88109b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data.\n",
    "data4 = pd.read_excel('Ghor El Safi  01-01-2000 ---  31-05-2022.xlsx',\n",
    "                      header=5, na_values=['Null'], parse_dates=['Date/Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dbb2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns.\n",
    "data4 = data4.drop(\n",
    "    columns=['Station', 'Manual Present Weather ', 'Cloud Type', 'Wind Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caf70075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new columns.\n",
    "data4['Area'] = 'Ghor El Safi'\n",
    "data4['Latitude'] = 31.02\n",
    "data4['Longitude'] = 35.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f87a65e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace (sky obscured or cloud amount cannot be estimated) with Nan value.\n",
    "data4['Clouds Cover (Okta)'] = data4['Clouds Cover (Okta)'].replace(\n",
    "    r'sky obscured or cloud amount cannot be estimated', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3fe6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the columns.\n",
    "data4.insert(1, 'Area', data4.pop('Area'))\n",
    "data4.insert(2, 'Latitude', data4.pop('Latitude'))\n",
    "data4.insert(3, 'Longitude', data4.pop('Longitude'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70d8955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42324 entries, 0 to 42323\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   Date/Time                    42324 non-null  datetime64[ns]\n",
      " 1   Area                         42324 non-null  object        \n",
      " 2   Latitude                     42324 non-null  float64       \n",
      " 3   Longitude                    42324 non-null  float64       \n",
      " 4   Air Dew Point                42324 non-null  float64       \n",
      " 5   Air Temperature (OC)         42324 non-null  float64       \n",
      " 6   Humidity %                   42324 non-null  float64       \n",
      " 7   Atmospheric Pressure         42324 non-null  float64       \n",
      " 8   Liquid Precipitation         42324 non-null  float64       \n",
      " 9   Clouds Cover (Okta)          42324 non-null  float64       \n",
      " 10  Cloud Cover %                42324 non-null  float64       \n",
      " 11  Snow Depth                   42324 non-null  float64       \n",
      " 12  Horizontal Visibility In m.  42324 non-null  float64       \n",
      " 13  Wind Direction (Degrees)     42324 non-null  float64       \n",
      " 14  Wind Speed (MPS)             42324 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(13), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Fixing missing data.\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data4['Snow Depth'].values.reshape(-1, 1))\n",
    "data4['Snow Depth'] = simpleImputer.transform(\n",
    "    data4['Snow Depth'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data4['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "data4['Wind Direction (Degrees)'] = simpleImputer.transform(\n",
    "    data4['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data4.iloc[:, 4:11])\n",
    "data4.iloc[:, 4:11] = simpleImputer.transform(data4.iloc[:, 4:11])\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data4['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "data4['Horizontal Visibility In m.'] = simpleImputer.transform(\n",
    "    data4['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data4['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data4['Wind Speed (MPS)'] = simpleImputer.transform(\n",
    "    data4['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e499e4f",
   "metadata": {},
   "source": [
    "# Dataset5 (Irwaished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a1fc48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data.\n",
    "data5 = pd.read_excel('Irwaished  01-01-2000 --- 31-10-2021.xlsx',\n",
    "                      header=5, na_values=['Null'], parse_dates=['Date/Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c452ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns.\n",
    "data5 = data5.drop(\n",
    "    columns=['Station', 'Manual Present Weather ', 'Cloud Type', 'Wind Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a15dce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new columns.\n",
    "data5['Area'] = 'Irwaished'\n",
    "data5['Latitude'] = 32.30\n",
    "data5['Longitude'] = 38.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cba7ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace (sky obscured or cloud amount cannot be estimated) with Nan value.\n",
    "data5['Clouds Cover (Okta)'] = data5['Clouds Cover (Okta)'].replace(\n",
    "    r'sky obscured or cloud amount cannot be estimated', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b55f6f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the columns.\n",
    "data5.insert(1, 'Area', data5.pop('Area'))\n",
    "data5.insert(2, 'Latitude', data5.pop('Latitude'))\n",
    "data5.insert(3, 'Longitude', data5.pop('Longitude'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8dc4d336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41823 entries, 0 to 41822\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   Date/Time                    41823 non-null  datetime64[ns]\n",
      " 1   Area                         41823 non-null  object        \n",
      " 2   Latitude                     41823 non-null  float64       \n",
      " 3   Longitude                    41823 non-null  float64       \n",
      " 4   Air Dew Point                41823 non-null  float64       \n",
      " 5   Air Temperature (OC)         41823 non-null  float64       \n",
      " 6   Humidity %                   41823 non-null  float64       \n",
      " 7   Atmospheric Pressure         41823 non-null  float64       \n",
      " 8   Liquid Precipitation         41823 non-null  float64       \n",
      " 9   Clouds Cover (Okta)          41823 non-null  float64       \n",
      " 10  Cloud Cover %                41823 non-null  float64       \n",
      " 11  Snow Depth                   41823 non-null  float64       \n",
      " 12  Horizontal Visibility In m.  41823 non-null  float64       \n",
      " 13  Wind Direction (Degrees)     41823 non-null  float64       \n",
      " 14  Wind Speed (MPS)             41823 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(13), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Fixing missing data.\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data5['Snow Depth'].values.reshape(-1, 1))\n",
    "data5['Snow Depth'] = simpleImputer.transform(\n",
    "    data5['Snow Depth'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data5['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "data5['Wind Direction (Degrees)'] = simpleImputer.transform(\n",
    "    data5['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data5.iloc[:, 4:11])\n",
    "data5.iloc[:, 4:11] = simpleImputer.transform(data5.iloc[:, 4:11])\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data5['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "data5['Horizontal Visibility In m.'] = simpleImputer.transform(\n",
    "    data5['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data5['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data5['Wind Speed (MPS)'] = simpleImputer.transform(\n",
    "    data5['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data5.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c84b6",
   "metadata": {},
   "source": [
    "# Dataset6 (Maan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a342f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data.\n",
    "data6 = pd.read_excel('Maan   01-01-2000 ---   31-05-2022.xlsx',\n",
    "                      header=5, na_values=['Null'], parse_dates=['Date/Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0319892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns.\n",
    "data6 = data6.drop(\n",
    "    columns=['Station', 'Manual Present Weather ', 'Cloud Type', 'Wind Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8eaaa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new columns.\n",
    "data6['Area'] = 'Maan'\n",
    "data6['Latitude'] = 30.10\n",
    "data6['Longitude'] = 35.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4232081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace (sky obscured or cloud amount cannot be estimated) with Nan value.\n",
    "data6['Clouds Cover (Okta)'] = data6['Clouds Cover (Okta)'].replace(\n",
    "    r'sky obscured or cloud amount cannot be estimated', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f210c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the columns.\n",
    "data6.insert(1, 'Area', data6.pop('Area'))\n",
    "data6.insert(2, 'Latitude', data6.pop('Latitude'))\n",
    "data6.insert(3, 'Longitude', data6.pop('Longitude'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b26ccc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48610 entries, 0 to 48609\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   Date/Time                    48610 non-null  datetime64[ns]\n",
      " 1   Area                         48610 non-null  object        \n",
      " 2   Latitude                     48610 non-null  float64       \n",
      " 3   Longitude                    48610 non-null  float64       \n",
      " 4   Air Dew Point                48610 non-null  float64       \n",
      " 5   Air Temperature (OC)         48610 non-null  float64       \n",
      " 6   Humidity %                   48610 non-null  float64       \n",
      " 7   Atmospheric Pressure         48610 non-null  float64       \n",
      " 8   Liquid Precipitation         48610 non-null  float64       \n",
      " 9   Clouds Cover (Okta)          48610 non-null  float64       \n",
      " 10  Cloud Cover %                48610 non-null  float64       \n",
      " 11  Snow Depth                   48610 non-null  float64       \n",
      " 12  Horizontal Visibility In m.  48610 non-null  float64       \n",
      " 13  Wind Direction (Degrees)     48610 non-null  float64       \n",
      " 14  Wind Speed (MPS)             48610 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(13), object(1)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# %%% Fixing missing data.\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data6['Snow Depth'].values.reshape(-1, 1))\n",
    "data6['Snow Depth'] = simpleImputer.transform(\n",
    "    data6['Snow Depth'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data6['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "data6['Wind Direction (Degrees)'] = simpleImputer.transform(\n",
    "    data6['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data6.iloc[:, 4:11])\n",
    "data6.iloc[:, 4:11] = simpleImputer.transform(data6.iloc[:, 4:11])\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data6['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "data6['Horizontal Visibility In m.'] = simpleImputer.transform(\n",
    "    data6['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data6['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data6['Wind Speed (MPS)'] = simpleImputer.transform(\n",
    "    data6['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data6.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8150d3b",
   "metadata": {},
   "source": [
    "# Dataset7 (Mafraq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b07a9956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data.\n",
    "data7 = pd.read_excel('Mafraq   01-01-2000  ---  31-05-2022.xlsx',\n",
    "                      header=5, na_values=['Null'], parse_dates=['Date/Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56ac417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns.\n",
    "data7 = data7.drop(\n",
    "    columns=['Station', 'Manual Present Weather ', 'Cloud Type', 'Wind Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab1392d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new columns.\n",
    "data7['Area'] = 'Mafraq'\n",
    "data7['Latitude'] = 32.22\n",
    "data7['Longitude'] = 36.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3196728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace (sky obscured or cloud amount cannot be estimated) with Nan value.\n",
    "data7['Clouds Cover (Okta)'] = data7['Clouds Cover (Okta)'].replace(\n",
    "    r'sky obscured or cloud amount cannot be estimated', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0bc3373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the columns.\n",
    "data7.insert(1, 'Area', data7.pop('Area'))\n",
    "data7.insert(2, 'Latitude', data7.pop('Latitude'))\n",
    "data7.insert(3, 'Longitude', data7.pop('Longitude'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a1b1d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55016 entries, 0 to 55015\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   Date/Time                    55016 non-null  datetime64[ns]\n",
      " 1   Area                         55016 non-null  object        \n",
      " 2   Latitude                     55016 non-null  float64       \n",
      " 3   Longitude                    55016 non-null  float64       \n",
      " 4   Air Dew Point                55016 non-null  float64       \n",
      " 5   Air Temperature (OC)         55016 non-null  float64       \n",
      " 6   Humidity %                   55016 non-null  float64       \n",
      " 7   Atmospheric Pressure         55016 non-null  float64       \n",
      " 8   Liquid Precipitation         55016 non-null  float64       \n",
      " 9   Clouds Cover (Okta)          55016 non-null  float64       \n",
      " 10  Cloud Cover %                55016 non-null  float64       \n",
      " 11  Snow Depth                   55016 non-null  float64       \n",
      " 12  Horizontal Visibility In m.  55016 non-null  float64       \n",
      " 13  Wind Direction (Degrees)     55016 non-null  float64       \n",
      " 14  Wind Speed (MPS)             55016 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(13), object(1)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Fixing missing data.\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data7['Snow Depth'].values.reshape(-1, 1))\n",
    "data7['Snow Depth'] = simpleImputer.transform(\n",
    "    data7['Snow Depth'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data7['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "data7['Wind Direction (Degrees)'] = simpleImputer.transform(\n",
    "    data7['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data7.iloc[:, 4:11])\n",
    "data7.iloc[:, 4:11] = simpleImputer.transform(data7.iloc[:, 4:11])\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data7['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "data7['Horizontal Visibility In m.'] = simpleImputer.transform(\n",
    "    data7['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data7['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data7['Wind Speed (MPS)'] = simpleImputer.transform(\n",
    "    data7['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data7.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e2123",
   "metadata": {},
   "source": [
    "# Dataset8 (Safawi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2601de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data.\n",
    "data8 = pd.read_excel('Safawi   01-01-2000 ---  31-05-2022.xlsx',\n",
    "                      header=5, na_values=['Null'], parse_dates=['Date/Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1dc111b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns.\n",
    "data8 = data8.drop(\n",
    "    columns=['Station', 'Manual Present Weather ', 'Cloud Type', 'Wind Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb9cdd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new columns.\n",
    "data8['Area'] = 'Safawi'\n",
    "data8['Latitude'] = 32.0939\n",
    "data8['Longitude'] = 37.0914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc662455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace (sky obscured or cloud amount cannot be estimated) with Nan value.\n",
    "data8['Clouds Cover (Okta)'] = data8['Clouds Cover (Okta)'].replace(\n",
    "    r'sky obscured or cloud amount cannot be estimated', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e49d63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the columns.\n",
    "data8.insert(1, 'Area', data8.pop('Area'))\n",
    "data8.insert(2, 'Latitude', data8.pop('Latitude'))\n",
    "data8.insert(3, 'Longitude', data8.pop('Longitude'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c23df9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53691 entries, 0 to 53690\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   Date/Time                    53691 non-null  datetime64[ns]\n",
      " 1   Area                         53691 non-null  object        \n",
      " 2   Latitude                     53691 non-null  float64       \n",
      " 3   Longitude                    53691 non-null  float64       \n",
      " 4   Air Dew Point                53691 non-null  float64       \n",
      " 5   Air Temperature (OC)         53691 non-null  float64       \n",
      " 6   Humidity %                   53691 non-null  float64       \n",
      " 7   Atmospheric Pressure         53691 non-null  float64       \n",
      " 8   Liquid Precipitation         53691 non-null  float64       \n",
      " 9   Clouds Cover (Okta)          53691 non-null  float64       \n",
      " 10  Cloud Cover %                53691 non-null  float64       \n",
      " 11  Snow Depth                   53691 non-null  float64       \n",
      " 12  Horizontal Visibility In m.  53691 non-null  float64       \n",
      " 13  Wind Direction (Degrees)     53691 non-null  float64       \n",
      " 14  Wind Speed (MPS)             53691 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(13), object(1)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Fixing missing data.\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data8['Snow Depth'].values.reshape(-1, 1))\n",
    "data8['Snow Depth'] = simpleImputer.transform(\n",
    "    data8['Snow Depth'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(data8['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "data8['Wind Direction (Degrees)'] = simpleImputer.transform(\n",
    "    data8['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data8.iloc[:, 4:11])\n",
    "data8.iloc[:, 4:11] = simpleImputer.transform(data8.iloc[:, 4:11])\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data8['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "data8['Horizontal Visibility In m.'] = simpleImputer.transform(\n",
    "    data8['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(data8['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data8['Wind Speed (MPS)'] = simpleImputer.transform(\n",
    "    data8['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "data8.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b54a8a",
   "metadata": {},
   "source": [
    "# Group every 3 hours togather.\n",
    "Three of the datasets consist of data with one-hour interval here we are going transform the datasets from one-hour to three-hour intervals to match with the other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eaef54c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = data1.groupby(pd.Grouper(freq='3H', key='Date/Time')).mean()\n",
    "\n",
    "d2 = data2.groupby(pd.Grouper(freq='3H', key='Date/Time')).mean()\n",
    "\n",
    "d3 = data3.groupby(pd.Grouper(freq='3H', key='Date/Time')).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc3333cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new columns.\n",
    "d1['Date/Time'] = d1.index\n",
    "d1['Area'] = 'Amman Airport'\n",
    "\n",
    "d2['Date/Time'] = d2.index\n",
    "d2['Area'] = 'Aqaba Airport'\n",
    "\n",
    "d3['Date/Time'] = d3.index\n",
    "d3['Area'] = 'Queen Alia Airport'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b593f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the columns.\n",
    "d1.insert(0, 'Date/Time', d1.pop('Date/Time'))\n",
    "d1.insert(1, 'Area', d1.pop('Area'))\n",
    "\n",
    "d2.insert(0, 'Date/Time', d2.pop('Date/Time'))\n",
    "d2.insert(1, 'Area', d2.pop('Area'))\n",
    "\n",
    "d3.insert(0, 'Date/Time', d3.pop('Date/Time'))\n",
    "d3.insert(1, 'Area', d3.pop('Area'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8968f23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 65495 entries, 2000-01-01 00:00:00 to 2022-05-31 18:00:00\n",
      "Freq: 3H\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   Date/Time                    65495 non-null  datetime64[ns]\n",
      " 1   Area                         65495 non-null  object        \n",
      " 2   Latitude                     65495 non-null  float64       \n",
      " 3   Longitude                    65495 non-null  float64       \n",
      " 4   Air Dew Point                65495 non-null  float64       \n",
      " 5   Air Temperature (OC)         65495 non-null  float64       \n",
      " 6   Humidity %                   65495 non-null  float64       \n",
      " 7   Atmospheric Pressure         65495 non-null  float64       \n",
      " 8   Liquid Precipitation         65495 non-null  float64       \n",
      " 9   Clouds Cover (Okta)          65495 non-null  float64       \n",
      " 10  Cloud Cover %                65495 non-null  float64       \n",
      " 11  Snow Depth                   65495 non-null  float64       \n",
      " 12  Horizontal Visibility In m.  65495 non-null  float64       \n",
      " 13  Wind Direction (Degrees)     65495 non-null  float64       \n",
      " 14  Wind Speed (MPS)             65495 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(13), object(1)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Fixing missing data in d1.\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(d1['Snow Depth'].values.reshape(-1, 1))\n",
    "d1['Snow Depth'] = simpleImputer.transform(\n",
    "    d1['Snow Depth'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(d1['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "d1['Wind Direction (Degrees)'] = simpleImputer.transform(\n",
    "    d1['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(d1.iloc[:, 4:11])\n",
    "d1.iloc[:, 4:11] = simpleImputer.transform(d1.iloc[:, 4:11])\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(d1['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "d1['Horizontal Visibility In m.'] = simpleImputer.transform(\n",
    "    d1['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(d1['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "d1['Wind Speed (MPS)'] = simpleImputer.transform(\n",
    "    d1['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=31.59)\n",
    "simpleImputer.fit(d1['Latitude'].values.reshape(-1, 1))\n",
    "d1['Latitude'] = simpleImputer.transform(d1['Latitude'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=35.59)\n",
    "simpleImputer.fit(d1['Longitude'].values.reshape(-1, 1))\n",
    "d1['Longitude'] = simpleImputer.transform(\n",
    "    d1['Longitude'].values.reshape(-1, 1))\n",
    "d1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c2233cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 65495 entries, 2000-01-01 00:00:00 to 2022-05-31 18:00:00\n",
      "Freq: 3H\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   Date/Time                    65495 non-null  datetime64[ns]\n",
      " 1   Area                         65495 non-null  object        \n",
      " 2   Latitude                     65495 non-null  float64       \n",
      " 3   Longitude                    65495 non-null  float64       \n",
      " 4   Air Dew Point                65495 non-null  float64       \n",
      " 5   Air Temperature (OC)         65495 non-null  float64       \n",
      " 6   Humidity %                   65495 non-null  float64       \n",
      " 7   Atmospheric Pressure         65495 non-null  float64       \n",
      " 8   Liquid Precipitation         65495 non-null  float64       \n",
      " 9   Clouds Cover (Okta)          65495 non-null  float64       \n",
      " 10  Cloud Cover %                65495 non-null  float64       \n",
      " 11  Snow Depth                   65495 non-null  float64       \n",
      " 12  Horizontal Visibility In m.  65495 non-null  float64       \n",
      " 13  Wind Direction (Degrees)     65495 non-null  float64       \n",
      " 14  Wind Speed (MPS)             65495 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(13), object(1)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Fixing missing data in d2.\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(d2['Snow Depth'].values.reshape(-1, 1))\n",
    "d2['Snow Depth'] = simpleImputer.transform(\n",
    "    d2['Snow Depth'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(d2['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "d2['Wind Direction (Degrees)'] = simpleImputer.transform(\n",
    "    d2['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(d2.iloc[:, 4:11])\n",
    "d2.iloc[:, 4:11] = simpleImputer.transform(d2.iloc[:, 4:11])\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(d2['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "d2['Horizontal Visibility In m.'] = simpleImputer.transform(\n",
    "    d2['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(d2['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "d2['Wind Speed (MPS)'] = simpleImputer.transform(\n",
    "    d2['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=29.33)\n",
    "simpleImputer.fit(d2['Latitude'].values.reshape(-1, 1))\n",
    "d2['Latitude'] = simpleImputer.transform(d2['Latitude'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=35)\n",
    "simpleImputer.fit(d2['Longitude'].values.reshape(-1, 1))\n",
    "d2['Longitude'] = simpleImputer.transform(\n",
    "    d2['Longitude'].values.reshape(-1, 1))\n",
    "d2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f96397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 67024 entries, 2000-01-01 00:00:00 to 2022-12-08 21:00:00\n",
      "Freq: 3H\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   Date/Time                    67024 non-null  datetime64[ns]\n",
      " 1   Area                         67024 non-null  object        \n",
      " 2   Latitude                     67024 non-null  float64       \n",
      " 3   Longitude                    67024 non-null  float64       \n",
      " 4   Air Dew Point                67024 non-null  float64       \n",
      " 5   Air Temperature (OC)         67024 non-null  float64       \n",
      " 6   Humidity %                   67024 non-null  float64       \n",
      " 7   Atmospheric Pressure         67024 non-null  float64       \n",
      " 8   Liquid Precipitation         67024 non-null  float64       \n",
      " 9   Clouds Cover (Okta)          67024 non-null  float64       \n",
      " 10  Cloud Cover %                67024 non-null  float64       \n",
      " 11  Snow Depth                   67024 non-null  float64       \n",
      " 12  Horizontal Visibility In m.  67024 non-null  float64       \n",
      " 13  Wind Direction (Degrees)     67024 non-null  float64       \n",
      " 14  Wind Speed (MPS)             67024 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(13), object(1)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Fixing missing data in d3.\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(d3['Snow Depth'].values.reshape(-1, 1))\n",
    "d3['Snow Depth'] = simpleImputer.transform(\n",
    "    d3['Snow Depth'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "simpleImputer.fit(d3['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "d3['Wind Direction (Degrees)'] = simpleImputer.transform(\n",
    "    d3['Wind Direction (Degrees)'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(d3.iloc[:, 4:11])\n",
    "d3.iloc[:, 4:11] = simpleImputer.transform(d3.iloc[:, 4:11])\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(d3['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "d3['Horizontal Visibility In m.'] = simpleImputer.transform(\n",
    "    d3['Horizontal Visibility In m.'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "simpleImputer.fit(d3['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "d3['Wind Speed (MPS)'] = simpleImputer.transform(\n",
    "    d3['Wind Speed (MPS)'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=31.43)\n",
    "simpleImputer.fit(d3['Latitude'].values.reshape(-1, 1))\n",
    "d3['Latitude'] = simpleImputer.transform(d3['Latitude'].values.reshape(-1, 1))\n",
    "\n",
    "simpleImputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy='constant', fill_value=35.59)\n",
    "simpleImputer.fit(d3['Longitude'].values.reshape(-1, 1))\n",
    "d3['Longitude'] = simpleImputer.transform(\n",
    "    d3['Longitude'].values.reshape(-1, 1))\n",
    "d3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5402c1b4",
   "metadata": {},
   "source": [
    "# Combining all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd0af1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 439478 entries, 0 to 439477\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count   Dtype         \n",
      "---  ------                       --------------   -----         \n",
      " 0   Date/Time                    439478 non-null  datetime64[ns]\n",
      " 1   Area                         439478 non-null  object        \n",
      " 2   Latitude                     439478 non-null  float64       \n",
      " 3   Longitude                    439478 non-null  float64       \n",
      " 4   Air Dew Point                439478 non-null  float64       \n",
      " 5   Air Temperature (OC)         439478 non-null  float64       \n",
      " 6   Humidity %                   439478 non-null  float64       \n",
      " 7   Atmospheric Pressure         439478 non-null  float64       \n",
      " 8   Liquid Precipitation         439478 non-null  float64       \n",
      " 9   Clouds Cover (Okta)          439478 non-null  float64       \n",
      " 10  Cloud Cover %                439478 non-null  float64       \n",
      " 11  Snow Depth                   439478 non-null  float64       \n",
      " 12  Horizontal Visibility In m.  439478 non-null  float64       \n",
      " 13  Wind Direction (Degrees)     439478 non-null  float64       \n",
      " 14  Wind Speed (MPS)             439478 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(13), object(1)\n",
      "memory usage: 50.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([d1, d2, d3, data4, data5, data6,data7, data8], ignore_index=True)\n",
    "df.isna().sum()\n",
    "df.info()\n",
    "df.nunique()\n",
    "old_data=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95468cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Date/Time to numeric.\n",
    "df['Date/Time'] = df['Date/Time'].astype(str)\n",
    "df['Date/Time'] = pd.to_datetime(df['Date/Time'], format='%Y-%m-%dT%H:%M:%S')\n",
    "df['Date/Time'] = pd.to_numeric(pd.to_datetime(df['Date/Time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58be63be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding.\n",
    "le = LabelEncoder()\n",
    "df['Area'] = le.fit_transform(df['Area'])\n",
    "df['Longitude'] = le.fit_transform(df['Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "009bcd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set.\n",
    "X = df.iloc[:,[0,1,2,3,4,7,10]].values\n",
    "y = df.iloc[:,[5,6,8,11,12,13,14]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cda14b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling.\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "y_train=sc.fit_transform(y_train)\n",
    "y_test=sc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "321c9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the ANN model\n",
    "ann = tf.keras.models.Sequential()# Initializing the ANN\n",
    "ann.add(tf.keras.layers.Dense(units=7,  activation='relu'))# Adding the input layer and the first hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=5, activation='relu'))# Adding the second hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=10, activation='relu'))# Adding the second hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=15, activation='relu'))# Adding the second hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=5, activation='relu'))# Adding the second hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=7,  activation='elu'))# Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4c400b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "12361/12361 [==============================] - 16s 1ms/step - loss: 0.8290 - accuracy: 0.3620\n",
      "Epoch 2/30\n",
      "12361/12361 [==============================] - 14s 1ms/step - loss: 0.7736 - accuracy: 0.3940\n",
      "Epoch 3/30\n",
      "12361/12361 [==============================] - 14s 1ms/step - loss: 0.7655 - accuracy: 0.4017\n",
      "Epoch 4/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7628 - accuracy: 0.4045\n",
      "Epoch 5/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7610 - accuracy: 0.4057\n",
      "Epoch 6/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7597 - accuracy: 0.4082\n",
      "Epoch 7/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7585 - accuracy: 0.4110\n",
      "Epoch 8/30\n",
      "12361/12361 [==============================] - 14s 1ms/step - loss: 0.7575 - accuracy: 0.4122\n",
      "Epoch 9/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7570 - accuracy: 0.4115\n",
      "Epoch 10/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7564 - accuracy: 0.4126\n",
      "Epoch 11/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7557 - accuracy: 0.4122\n",
      "Epoch 12/30\n",
      "12361/12361 [==============================] - 14s 1ms/step - loss: 0.7554 - accuracy: 0.4125\n",
      "Epoch 13/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7550 - accuracy: 0.4121\n",
      "Epoch 14/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7548 - accuracy: 0.4124\n",
      "Epoch 15/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7543 - accuracy: 0.4121\n",
      "Epoch 16/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7538 - accuracy: 0.4124\n",
      "Epoch 17/30\n",
      "12361/12361 [==============================] - 14s 1ms/step - loss: 0.7535 - accuracy: 0.4127\n",
      "Epoch 18/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7530 - accuracy: 0.4134\n",
      "Epoch 19/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7526 - accuracy: 0.4140\n",
      "Epoch 20/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7525 - accuracy: 0.4142\n",
      "Epoch 21/30\n",
      "12361/12361 [==============================] - 14s 1ms/step - loss: 0.7524 - accuracy: 0.4141\n",
      "Epoch 22/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7521 - accuracy: 0.4139\n",
      "Epoch 23/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7518 - accuracy: 0.4146\n",
      "Epoch 24/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7515 - accuracy: 0.4141\n",
      "Epoch 25/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7517 - accuracy: 0.4143\n",
      "Epoch 26/30\n",
      "12361/12361 [==============================] - 14s 1ms/step - loss: 0.7514 - accuracy: 0.4145\n",
      "Epoch 27/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7512 - accuracy: 0.4147\n",
      "Epoch 28/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7512 - accuracy: 0.4144\n",
      "Epoch 29/30\n",
      "12361/12361 [==============================] - 13s 1ms/step - loss: 0.7511 - accuracy: 0.4138\n",
      "Epoch 30/30\n",
      "12361/12361 [==============================] - 14s 1ms/step - loss: 0.7509 - accuracy: 0.4145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ba1a2dcf10>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the ANN model.\n",
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])# Compiling the ANN\n",
    "ann.fit(X_train, y_train, epochs = 30)# Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "137b0fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1374/1374 [==============================] - 1s 939us/step\n",
      "Accuracy = 0.47\n"
     ]
    }
   ],
   "source": [
    "# Making the predictions and evaluating the model.\n",
    "y_pred = ann.predict(X_test)# #Predicting the Test set results\n",
    "\n",
    "print(\"Accuracy =\", round(sm.mean_absolute_error(y_test, y_pred), 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d94eea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding.\n",
    "# # %% Decoding.\n",
    "# y_pred= sc.inverse_transform(y_pred)\n",
    "# y_train= sc.inverse_transform(y_train)\n",
    "# y_test= sc.inverse_transform(y_test)\n",
    "# X_train=sc.inverse_transform(X_train.reshape(-14, 14))\n",
    "# X_test=sc.inverse_transform(X_test.reshape(-2, 2))\n",
    "\n",
    "# df['Longitude'] = le.inverse_transform(df['Longitude'])\n",
    "# df['Area'] = le.inverse_transform(df['Area'])\n",
    "# df['Date/Time'] = pd.to_datetime(df['Date/Time'],format='%Y-%m-%dT%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2c01decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting future values.\n",
    "# new_data = pd.read_excel('Test.xlsx' , parse_dates=['Date/Time'])\n",
    "# new_data['Date/Time'] = new_data['Date/Time'].astype(str)\n",
    "# new_data['Date/Time'] = pd.to_datetime(new_data['Date/Time'], format='%Y-%m-%dT%H:%M:%S')\n",
    "# new_data['Date/Time'] = pd.to_numeric(pd.to_datetime(new_data['Date/Time']))\n",
    "\n",
    "# new_pred = ann.predict(new_data)\n",
    "\n",
    "# new_data['Date/Time'] = pd.to_datetime(new_data['Date/Time'],format='%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "# new_data = pd.concat([new_data,new_pred],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d0b0af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data[\"Day\"] = new_data['Date/Time'].dt.day\n",
    "# new_data[\"Time\"] = new_data['Date/Time'].dt.time\n",
    "# new_data[\"Year\"] = new_data['Date/Time'].dt.year\n",
    "# new_data[\"Month\"] = new_data['Date/Time'].dt.month\n",
    "\n",
    "#new_data.groupby([\"Month\",\"Day\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1fe955a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_data[\"Day\"] = old_data['Date/Time'].dt.day\n",
    "# old_data[\"Time\"] = old_data['Date/Time'].dt.time\n",
    "# old_data[\"Year\"] = old_data['Date/Time'].dt.year\n",
    "# old_data[\"Month\"] = old_data['Date/Time'].dt.month\n",
    "\n",
    "#old_data.groupby([\"Month\",\"Day\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "64aa1953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cc= new_data-old_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c5934f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.line(df,x = 'Date/Time', y = ['Humidity %'], template = 'plotly_dark', title = 'Variation of Humidity with Time')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6f0855d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.line(df,x = 'Date/Time', y = ['Cloud Cover %','Clouds Cover (Okta)'], template = 'plotly_dark', title = 'Variation of Humidity with Time')\n",
    "# fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
